model:
  NAME: PTSegV2_Balance_Main
  in_channels: 6
  beta: 0.999 # 0.999
model_prior:
  NAME: PTSegV2_Balance_Prior
  in_channels: 6
  beta: 0.999 # 0.999

epochs: 100
batch_size: 2 # 2 for PTv2; 4 for PTv1

dataset:
  common:
    NAME: S3DIS
    data_root: data/S3DIS
    test_area: 5
    voxel_size: 0.04
    variable: True # whether to use the original number of points. The number of point per point cloud is variable. Defaults to False.
  train:
    split: train
    voxel_max: 40000 # difference from 24000 in pointnet++; 40000 for PTNet (limit for the GPU memory)
    loop: 30  # here, the training has been looped 30 times. therefore, the training epochs do not need much.
    presample: False
    sources: False # load different scene data to "main" and "prior" branch
    views: True # put different aug on "main" and "prior" branch input data
    views_source: True # if select True, the "prior" branch use raw data without augmentation
    contact_minor: False # contact minor class scene, default: False
  val:
    split: val
    voxel_max: null
    presample: True 
  test:
    split: test
    voxel_max: null
    presample: False 

dataloader:
  num_workers: 8

datatransforms:
  train: [ChromaticAutoContrast, PointsToTensor, PointCloudScaling, PointCloudRotation, PointCloudJitter, ChromaticDropGPU, ChromaticNormalize]
  val: [PointsToTensor, ChromaticNormalize]
  kwargs:
    color_drop: 0.1
    gravity_dim: 2
    scale: [0.9, 1.1]
    angle: [0, 0, 1]
    jitter_sigma: 0.005
    jitter_clip: 0.02
    mean_std: False

criterion:
  NAME: CrossEntropy
  label_smoothing: 0.2
criterion_SupCon:
  NAME: SupConLoss
  temperature: 0.07

optimizer:
  NAME: 'adamw'  # performs 1 point better than adam
  weight_decay: 1.0e-4

# lr_scheduler2:
sched: cosine
warmup_epochs: 0
min_lr: 1.0e-5
lr: 0.01  # 'sgd':0.1; 'adamw':0.01

# loss_weight
loss_prior: 1.0
loss_prior_supcon: 1.0
loss_main_l1: 1.0
loss_main_ce: 1.0
